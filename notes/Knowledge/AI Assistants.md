# AI Assistants

## UI Characteristics
1. Voice input
2. Natural language can talk as you like to it
3. Voice output
4. Intelligent interpretation (can also use context besides just the voice input)
5. Agency (performs actions the user didn't request, they can take initiative on actions)

The hidden sixth: integration with other apps

## Evaluating AI Assistants
When evaluating the user experience of [[AI Assistants]], we need to consider its 5 technologies and their integration (6 in total)

## Advantages 
When all 5 characteristics are applied, the interaction style has two advantages
- It can short-circuit the physical interface and simply allow users to formulate their goals in natural language. Although speaking does involve an [[Interaction Cost]], in theory, this cost is smaller than learning a new UI, pressing buttons, and making selections
- It can infer users’ goals and be proactive about them by offering appropriate suggestions based on contextual information or prior user behavior. This second aspect is closer to “reading our minds.”

## Today's standard (Anno 2018)
It fails all the characteristics and the integration (it sucks) for even slightly complex interactions. People essentially only use it when their hands are unavailable, or when it is faster to say that lookup

It only works for simple queries, and often you need to ask the question in a specific way to get a reasonable response

This is us adapting to AI, but UI should be the other way around, it should adapt to us

Asking the question in one go without an accent is the most reliable way to get an answer, but this goes against how the conversation between humans goes, with many uhms and pauses to find the correct word

## Voice vs Screens
Often users want a spoken response and not e.g. look at their phone for the answer

Further, when using the screen it should be easy to return to the question asked

## Partial Answers
E.g. when asking for house prices in a specific neighborhood, users were usually pleased if it gave the average house prices in the area

With the screen, it was more mixed, but most people were disappointed that the result wasn't spoken

## Trust In Results
In general, the participants didn't trust the results the assistants returned. The more evidence the assistant provided about its answers the better

## Poor Support For Comparision And Shopping
1. When speaking it takes a long time to list all the differences between two products
2. No way of going back and forth between options, all information had to be committed to [[Working Memory]]

It assumes [[Satisficing]]

## Skills And Action
Most people don't know that assistants can interact with other apps, and both Alexa skills and Google Actions are poorly designed

## Interacting With Skills
Alexa skills suck, they don't accept the relative free from natural language as Alexa does 

## Integration With Other Apps
Often vendors lock to the provider's apps (e.g. Apple and Apple Music), which is annoying for the user
